{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7201985,"sourceType":"datasetVersion","datasetId":4166062},{"sourceId":7500932,"sourceType":"datasetVersion","datasetId":4170172},{"sourceId":7501164,"sourceType":"datasetVersion","datasetId":4245933},{"sourceId":7508722,"sourceType":"datasetVersion","datasetId":4373104}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/espain/esp_train.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1=pd.read_csv(\"/kaggle/input/espain/esp_dev.csv\")\ndf1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2=pd.read_csv(\"/kaggle/input/espain/esp_dev_with_labels.csv\")\ndf2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3=pd.read_csv(\"/kaggle/input/espain/esp_test.csv\")\ndf3.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2['Text2'] = df2['Text'].apply(lambda x: x.split('\\n')[1] if '\\n' in x else '')\ndf2['Text2'] = df2['Text2'].str.replace('\\n', '')\ndf2['Text1'] = df2['Text'].apply(lambda x: x.split('\\n')[0] if '\\n' in x else '')\ndf2['Text1'] = df2['Text1'].str.replace('\\n', '')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3['Text2'] = df3['Text'].apply(lambda x: x.split('\\n')[1] if '\\n' in x else '')\ndf3['Text2'] = df3['Text2'].str.replace('\\n', '')\ndf3['Text1'] = df3['Text'].apply(lambda x: x.split('\\n')[0] if '\\n' in x else '')\ndf3['Text1'] = df3['Text1'].str.replace('\\n', '')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Text2'] = df['Text'].apply(lambda x: x.split('\\n')[1] if '\\n' in x else '')\ndf['Text2'] = df['Text2'].str.replace('\\n', '')\ndf['Text2'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1['Text2'] = df1['Text'].apply(lambda x: x.split('\\n')[1] if '\\n' in x else '')\ndf1['Text2'] = df1['Text2'].str.replace('\\n', '')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Text1'] = df['Text'].apply(lambda x: x.split('\\n')[0] if '\\n' in x else '')\ndf['Text1'] = df['Text1'].str.replace('\\n', '')\ndf['Text1'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1['Text1'] = df1['Text'].apply(lambda x: x.split('\\n')[0] if '\\n' in x else '')\ndf1['Text1'] = df1['Text1'].str.replace('\\n', '')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(columns=['Text'])\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport string","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# marathi_numerals_pattern = re.compile(r'[\\u0966-\\u096F]+')\n\n# # Function to remove Marathi numerals from a text\n# def remove_marathi_numerals(text):\n#     return marathi_numerals_pattern.sub('', text)\n\n# # Apply the function to the 'Text1' column\n# df['Text1'] = df['Text1'].apply(remove_marathi_numerals)\n# df['Text2'] = df['Text2'].apply(remove_marathi_numerals)\n# df1['Text1'] = df1['Text1'].apply(remove_marathi_numerals)\n# df1['Text2'] = df1['Text2'].apply(remove_marathi_numerals)\n# df2['Text1'] = df2['Text1'].apply(remove_marathi_numerals)\n# df2['Text2'] = df2['Text2'].apply(remove_marathi_numerals)\n# df3['Text1'] = df3['Text1'].apply(remove_marathi_numerals)\n# df3['Text2'] = df3['Text2'].apply(remove_marathi_numerals)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# spanish_alphabet_pattern = re.compile(r'\\D+')\n\n# # Apply the pattern to the 'Text' column\n# df['Text1'] = df['Text1'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\n# df['Text2'] = df['Text2'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\n\n# df1['Text1'] = df1['Text1'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\n# df1['Text2'] = df1['Text2'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\n# df2['Text1'] = df2['Text1'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\n# df2['Text2'] = df2['Text2'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\n# df3['Text1'] = df3['Text1'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\n# df3['Text2'] = df3['Text2'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pandas torch transformers\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Transformer-1**","metadata":{}},{"cell_type":"code","source":"pip install -U sentence-transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SentenceTransformer('jfarray/Model_dccuchile_bert-base-spanish-wwm-uncased_10_Epochs')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Assuming df is your DataFrame\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = df2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, SentencesDataset, LoggingHandler, losses\n\nmodel = SentenceTransformer('jfarray/Model_dccuchile_bert-base-spanish-wwm-uncased_10_Epochs')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom sentence_transformers.readers import InputExample\n\ntrain_examples = [InputExample(texts=[row['Text1'], row['Text2']], label=row['Score']) for _, row in train_df.iterrows()]\ntrain_dataset = SentencesDataset(train_examples, model)\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n\nval_examples = [InputExample(texts=[row['Text1'], row['Text2']], label=row['Score']) for _, row in val_df.iterrows()]\nval_dataset = SentencesDataset(val_examples, model)\nval_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=16)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.nn import BCEWithLogitsLoss\n\nloss_function = BCEWithLogitsLoss()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sentence_transformers import SentenceTransformer, InputExample, losses\nfrom sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\nfrom torch.utils.data import DataLoader\nimport torch\n\n# Initialize the model\nmodel = SentenceTransformer('jfarray/Model_dccuchile_bert-base-spanish-wwm-uncased_10_Epochs')# Define the cosine similarity loss function\nloss_function = losses.CosineSimilarityLoss(model)\n\n# Prepare the data\ntrain_examples = [InputExample(texts=[row['Text1'], row['Text2']], label=row['Score']) for _, row in train_df.iterrows()]\n\n# Create a DataLoader\ntrain_dataloader = DataLoader(train_examples, batch_size=16, shuffle=True)\n\nsentences1 = [example.texts[0] for example in val_examples]\nsentences2 = [example.texts[1] for example in val_examples]\nscores = [example.label for example in val_examples]\n\n# Create an evaluator using cosine similarity\nevaluator = EmbeddingSimilarityEvaluator(sentences1, sentences2, scores)\n\n# Adjust warm-up steps according to your preference\nwarmup_steps = 700\n\n\nmodel.fit(\n    train_objectives=[(train_dataloader, loss_function)],\n    epochs=10,\n    evaluator=evaluator,\n    optimizer_class= torch.optim.AdamW,\n    optimizer_params={'lr': 9e-5},\n    weight_decay=9.5e-7,  \n    evaluation_steps=1000,\n    warmup_steps=warmup_steps,\n    output_path='model3',\n    save_best_model=True,\n    show_progress_bar=True,\n    \n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SentenceTransformer('model3')\n\ndef compute_cosine_similarity(row):\n    embedding_1 = model.encode(row['Text1'], convert_to_tensor=True)\n    embedding_2 = model.encode(row['Text2'], convert_to_tensor=True)\n    similarity = util.pytorch_cos_sim(embedding_1, embedding_2)\n    return similarity.item()\n\n# Create a new column 'CosineSimilarity' and apply the function\ndf2['CosineSimilarity'] = df2.apply(compute_cosine_similarity, axis=1)\n\n# Display the updated DataFrame\n# print(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2['CosineSimilarity'] = df2['CosineSimilarity'].apply(lambda x: 0 if x < 0 else x)\ndf2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import spearmanr\n\n# Assuming df is your DataFrame\ncorrelation, _ = spearmanr(df2['Score'], df2['CosineSimilarity'])\n\nprint(f\"Spearman Correlation: {correlation}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3['CosineSimilarity'] = df3.apply(compute_cosine_similarity, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_df = df3.drop(columns=['Text1', 'Text2','Text'])\ntransformer_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_df = transformer_df.rename(columns={'CosineSimilarity': 'Pred_Score'})\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_df = df3.drop(columns=['Text1', 'Text2','Text'])\ntransformer_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_df = transformer_df.rename(columns={'CosineSimilarity': 'Pred_Score'})\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_df['Pred_Score'] = transformer_df['Pred_Score'].apply(lambda x: 0 if x < 0 else x)\ntransformer_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_df.to_csv(\"pred_mar_a.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}