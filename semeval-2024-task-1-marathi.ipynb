{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7201985,"sourceType":"datasetVersion","datasetId":4166062},{"sourceId":7500932,"sourceType":"datasetVersion","datasetId":4170172},{"sourceId":7501164,"sourceType":"datasetVersion","datasetId":4245933}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-29T07:45:25.412830Z","iopub.execute_input":"2024-01-29T07:45:25.413117Z","iopub.status.idle":"2024-01-29T07:45:26.295250Z","shell.execute_reply.started":"2024-01-29T07:45:25.413091Z","shell.execute_reply":"2024-01-29T07:45:26.294321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/semeval-mar/mar_train.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:26.296947Z","iopub.execute_input":"2024-01-29T07:45:26.297326Z","iopub.status.idle":"2024-01-29T07:45:26.343568Z","shell.execute_reply.started":"2024-01-29T07:45:26.297290Z","shell.execute_reply":"2024-01-29T07:45:26.342627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1=pd.read_csv(\"/kaggle/input/semeval-mar/mar_dev.csv\")\ndf1.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:26.344694Z","iopub.execute_input":"2024-01-29T07:45:26.344932Z","iopub.status.idle":"2024-01-29T07:45:26.363678Z","shell.execute_reply.started":"2024-01-29T07:45:26.344911Z","shell.execute_reply":"2024-01-29T07:45:26.362856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2=pd.read_csv(\"/kaggle/input/semeval-mar/mar_dev_with_labels.csv\")\ndf2.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:26.365779Z","iopub.execute_input":"2024-01-29T07:45:26.366076Z","iopub.status.idle":"2024-01-29T07:45:26.386134Z","shell.execute_reply.started":"2024-01-29T07:45:26.366050Z","shell.execute_reply":"2024-01-29T07:45:26.385152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3=pd.read_csv(\"/kaggle/input/semeval-mar/mar_test.csv\")\ndf3.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:26.387455Z","iopub.execute_input":"2024-01-29T07:45:26.388028Z","iopub.status.idle":"2024-01-29T07:45:26.409797Z","shell.execute_reply.started":"2024-01-29T07:45:26.387991Z","shell.execute_reply":"2024-01-29T07:45:26.408974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2['Text2'] = df2['Text'].apply(lambda x: x.split('\\n')[1] if '\\n' in x else '')\ndf2['Text2'] = df2['Text2'].str.replace('\\n', '')\ndf2['Text1'] = df2['Text'].apply(lambda x: x.split('\\n')[0] if '\\n' in x else '')\ndf2['Text1'] = df2['Text1'].str.replace('\\n', '')","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:26.410818Z","iopub.execute_input":"2024-01-29T07:45:26.411397Z","iopub.status.idle":"2024-01-29T07:45:26.421136Z","shell.execute_reply.started":"2024-01-29T07:45:26.411373Z","shell.execute_reply":"2024-01-29T07:45:26.420055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3['Text2'] = df3['Text'].apply(lambda x: x.split('\\n')[1] if '\\n' in x else '')\ndf3['Text2'] = df3['Text2'].str.replace('\\n', '')\ndf3['Text1'] = df3['Text'].apply(lambda x: x.split('\\n')[0] if '\\n' in x else '')\ndf3['Text1'] = df3['Text1'].str.replace('\\n', '')","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:26.422334Z","iopub.execute_input":"2024-01-29T07:45:26.422961Z","iopub.status.idle":"2024-01-29T07:45:26.434982Z","shell.execute_reply.started":"2024-01-29T07:45:26.422935Z","shell.execute_reply":"2024-01-29T07:45:26.434000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Text2'] = df['Text'].apply(lambda x: x.split('\\n')[1] if '\\n' in x else '')\ndf['Text2'] = df['Text2'].str.replace('\\n', '')\ndf['Text2'][0]","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:26.436381Z","iopub.execute_input":"2024-01-29T07:45:26.436686Z","iopub.status.idle":"2024-01-29T07:45:26.450459Z","shell.execute_reply.started":"2024-01-29T07:45:26.436662Z","shell.execute_reply":"2024-01-29T07:45:26.449539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1['Text2'] = df1['Text'].apply(lambda x: x.split('\\n')[1] if '\\n' in x else '')\ndf1['Text2'] = df1['Text2'].str.replace('\\n', '')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:26.451747Z","iopub.execute_input":"2024-01-29T07:45:26.452459Z","iopub.status.idle":"2024-01-29T07:45:26.462390Z","shell.execute_reply.started":"2024-01-29T07:45:26.452427Z","shell.execute_reply":"2024-01-29T07:45:26.461500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Text1'] = df['Text'].apply(lambda x: x.split('\\n')[0] if '\\n' in x else '')\ndf['Text1'] = df['Text1'].str.replace('\\n', '')\ndf['Text1'][0]","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:26.467583Z","iopub.execute_input":"2024-01-29T07:45:26.468199Z","iopub.status.idle":"2024-01-29T07:45:26.485583Z","shell.execute_reply.started":"2024-01-29T07:45:26.468159Z","shell.execute_reply":"2024-01-29T07:45:26.484425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1['Text1'] = df1['Text'].apply(lambda x: x.split('\\n')[0] if '\\n' in x else '')\ndf1['Text1'] = df1['Text1'].str.replace('\\n', '')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:26.486913Z","iopub.execute_input":"2024-01-29T07:45:26.487264Z","iopub.status.idle":"2024-01-29T07:45:26.495036Z","shell.execute_reply.started":"2024-01-29T07:45:26.487235Z","shell.execute_reply":"2024-01-29T07:45:26.494241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(columns=['Text'])\ndf","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:26.496234Z","iopub.execute_input":"2024-01-29T07:45:26.497103Z","iopub.status.idle":"2024-01-29T07:45:26.519899Z","shell.execute_reply.started":"2024-01-29T07:45:26.497067Z","shell.execute_reply":"2024-01-29T07:45:26.518891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:26.521032Z","iopub.execute_input":"2024-01-29T07:45:26.521862Z","iopub.status.idle":"2024-01-29T07:45:26.535212Z","shell.execute_reply.started":"2024-01-29T07:45:26.521830Z","shell.execute_reply":"2024-01-29T07:45:26.534085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport string","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"marathi_numerals_pattern = re.compile(r'[\\u0966-\\u096F]+')\n\n# Function to remove Marathi numerals from a text\ndef remove_marathi_numerals(text):\n    return marathi_numerals_pattern.sub('', text)\n\n# Apply the function to the 'Text1' column\ndf['Text1'] = df['Text1'].apply(remove_marathi_numerals)\ndf['Text2'] = df['Text2'].apply(remove_marathi_numerals)\ndf1['Text1'] = df1['Text1'].apply(remove_marathi_numerals)\ndf1['Text2'] = df1['Text2'].apply(remove_marathi_numerals)\ndf2['Text1'] = df2['Text1'].apply(remove_marathi_numerals)\ndf2['Text2'] = df2['Text2'].apply(remove_marathi_numerals)\ndf3['Text1'] = df3['Text1'].apply(remove_marathi_numerals)\ndf3['Text2'] = df3['Text2'].apply(remove_marathi_numerals)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spanish_alphabet_pattern = re.compile(r'\\D+')\n\n# Apply the pattern to the 'Text' column\ndf['Text1'] = df['Text1'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\ndf['Text2'] = df['Text2'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\n\ndf1['Text1'] = df1['Text1'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\ndf1['Text2'] = df1['Text2'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\ndf2['Text1'] = df2['Text1'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\ndf2['Text2'] = df2['Text2'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\ndf3['Text1'] = df3['Text1'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\ndf3['Text2'] = df3['Text2'].apply(lambda x: ''.join(spanish_alphabet_pattern.findall(x)))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pandas torch transformers\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:26.536361Z","iopub.execute_input":"2024-01-29T07:45:26.536802Z","iopub.status.idle":"2024-01-29T07:45:39.926231Z","shell.execute_reply.started":"2024-01-29T07:45:26.536763Z","shell.execute_reply":"2024-01-29T07:45:39.924902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Transformer-1**","metadata":{}},{"cell_type":"code","source":"pip install -U sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:39.927951Z","iopub.execute_input":"2024-01-29T07:45:39.928780Z","iopub.status.idle":"2024-01-29T07:45:54.681259Z","shell.execute_reply.started":"2024-01-29T07:45:39.928741Z","shell.execute_reply":"2024-01-29T07:45:54.680163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:45:54.682557Z","iopub.execute_input":"2024-01-29T07:45:54.682850Z","iopub.status.idle":"2024-01-29T07:46:00.408644Z","shell.execute_reply.started":"2024-01-29T07:45:54.682824Z","shell.execute_reply":"2024-01-29T07:46:00.407820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SentenceTransformer('l3cube-pune/marathi-sentence-similarity-sbert')","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:46:00.409713Z","iopub.execute_input":"2024-01-29T07:46:00.410102Z","iopub.status.idle":"2024-01-29T07:47:01.486354Z","shell.execute_reply.started":"2024-01-29T07:46:00.410078Z","shell.execute_reply":"2024-01-29T07:47:01.485345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:47:01.487544Z","iopub.execute_input":"2024-01-29T07:47:01.488020Z","iopub.status.idle":"2024-01-29T07:47:01.502974Z","shell.execute_reply.started":"2024-01-29T07:47:01.487991Z","shell.execute_reply":"2024-01-29T07:47:01.502032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Assuming df is your DataFrame\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:47:01.504097Z","iopub.execute_input":"2024-01-29T07:47:01.504705Z","iopub.status.idle":"2024-01-29T07:47:01.515465Z","shell.execute_reply.started":"2024-01-29T07:47:01.504677Z","shell.execute_reply":"2024-01-29T07:47:01.514647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=df","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:47:01.516429Z","iopub.execute_input":"2024-01-29T07:47:01.516661Z","iopub.status.idle":"2024-01-29T07:47:01.526131Z","shell.execute_reply.started":"2024-01-29T07:47:01.516640Z","shell.execute_reply":"2024-01-29T07:47:01.525326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = df2","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:47:01.527158Z","iopub.execute_input":"2024-01-29T07:47:01.527759Z","iopub.status.idle":"2024-01-29T07:47:01.536114Z","shell.execute_reply.started":"2024-01-29T07:47:01.527734Z","shell.execute_reply":"2024-01-29T07:47:01.535331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, SentencesDataset, LoggingHandler, losses\n\nmodel = SentenceTransformer('l3cube-pune/marathi-sentence-similarity-sbert')","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:47:01.537210Z","iopub.execute_input":"2024-01-29T07:47:01.537563Z","iopub.status.idle":"2024-01-29T07:47:02.790404Z","shell.execute_reply.started":"2024-01-29T07:47:01.537532Z","shell.execute_reply":"2024-01-29T07:47:02.789524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom sentence_transformers.readers import InputExample\n\ntrain_examples = [InputExample(texts=[row['Text1'], row['Text2']], label=row['Score']) for _, row in train_df.iterrows()]\ntrain_dataset = SentencesDataset(train_examples, model)\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n\nval_examples = [InputExample(texts=[row['Text1'], row['Text2']], label=row['Score']) for _, row in val_df.iterrows()]\nval_dataset = SentencesDataset(val_examples, model)\nval_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=16)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:47:02.791544Z","iopub.execute_input":"2024-01-29T07:47:02.791826Z","iopub.status.idle":"2024-01-29T07:47:02.902420Z","shell.execute_reply.started":"2024-01-29T07:47:02.791804Z","shell.execute_reply":"2024-01-29T07:47:02.901587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.nn import BCEWithLogitsLoss\n\nloss_function = BCEWithLogitsLoss()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:47:02.903695Z","iopub.execute_input":"2024-01-29T07:47:02.904008Z","iopub.status.idle":"2024-01-29T07:47:02.908190Z","shell.execute_reply.started":"2024-01-29T07:47:02.903981Z","shell.execute_reply":"2024-01-29T07:47:02.907206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sentence_transformers import SentenceTransformer, InputExample, losses\nfrom sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\nfrom torch.utils.data import DataLoader\nimport torch\n\n# Initialize the model\nmodel = SentenceTransformer('l3cube-pune/marathi-sentence-similarity-sbert')\n# Define the cosine similarity loss function\nloss_function = losses.CosineSimilarityLoss(model)\n\n# Prepare the data\ntrain_examples = [InputExample(texts=[row['Text1'], row['Text2']], label=row['Score']) for _, row in train_df.iterrows()]\n\n# Create a DataLoader\ntrain_dataloader = DataLoader(train_examples, batch_size=16, shuffle=True)\n\nsentences1 = [example.texts[0] for example in val_examples]\nsentences2 = [example.texts[1] for example in val_examples]\nscores = [example.label for example in val_examples]\n\n# Create an evaluator using cosine similarity\nevaluator = EmbeddingSimilarityEvaluator(sentences1, sentences2, scores)\n\n# Adjust warm-up steps according to your preference\nwarmup_steps = 750\n\n\nmodel.fit(\n    train_objectives=[(train_dataloader, loss_function)],\n    epochs=10,\n    evaluator=evaluator,\n    optimizer_class= torch.optim.AdamW,\n    optimizer_params={'lr': 9e-5},\n    weight_decay=5e-2,  \n    evaluation_steps=1000,\n    output_path='model3',\n    save_best_model=True,\n    show_progress_bar=True,\n    \n)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:47:02.909378Z","iopub.execute_input":"2024-01-29T07:47:02.910197Z","iopub.status.idle":"2024-01-29T07:50:09.024392Z","shell.execute_reply.started":"2024-01-29T07:47:02.910166Z","shell.execute_reply":"2024-01-29T07:50:09.023507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SentenceTransformer('model3')\n\ndef compute_cosine_similarity(row):\n    embedding_1 = model.encode(row['Text1'], convert_to_tensor=True)\n    embedding_2 = model.encode(row['Text2'], convert_to_tensor=True)\n    similarity = util.pytorch_cos_sim(embedding_1, embedding_2)\n    return similarity.item()\n\n# Create a new column 'CosineSimilarity' and apply the function\ndf2['CosineSimilarity'] = df2.apply(compute_cosine_similarity, axis=1)\n\n# Display the updated DataFrame\n# print(df)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:50:09.025955Z","iopub.execute_input":"2024-01-29T07:50:09.026258Z","iopub.status.idle":"2024-01-29T07:50:27.008459Z","shell.execute_reply.started":"2024-01-29T07:50:09.026232Z","shell.execute_reply":"2024-01-29T07:50:27.007569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2['CosineSimilarity'] = df2['CosineSimilarity'].apply(lambda x: 0 if x < 0 else x)\ndf2.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:50:27.009592Z","iopub.execute_input":"2024-01-29T07:50:27.009867Z","iopub.status.idle":"2024-01-29T07:50:27.022961Z","shell.execute_reply.started":"2024-01-29T07:50:27.009843Z","shell.execute_reply":"2024-01-29T07:50:27.022130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import spearmanr\n\n# Assuming df is your DataFrame\ncorrelation, _ = spearmanr(df2['Score'], df2['CosineSimilarity'])\n\nprint(f\"Spearman Correlation: {correlation}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:50:27.027977Z","iopub.execute_input":"2024-01-29T07:50:27.028349Z","iopub.status.idle":"2024-01-29T07:50:27.036188Z","shell.execute_reply.started":"2024-01-29T07:50:27.028306Z","shell.execute_reply":"2024-01-29T07:50:27.035339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3['CosineSimilarity'] = df3.apply(compute_cosine_similarity, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:50:27.037481Z","iopub.execute_input":"2024-01-29T07:50:27.038100Z","iopub.status.idle":"2024-01-29T07:50:44.070141Z","shell.execute_reply.started":"2024-01-29T07:50:27.038066Z","shell.execute_reply":"2024-01-29T07:50:44.069192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_df = df3.drop(columns=['Text1', 'Text2','Text'])\ntransformer_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:50:44.071403Z","iopub.execute_input":"2024-01-29T07:50:44.071690Z","iopub.status.idle":"2024-01-29T07:50:44.082258Z","shell.execute_reply.started":"2024-01-29T07:50:44.071665Z","shell.execute_reply":"2024-01-29T07:50:44.081330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_df = transformer_df.rename(columns={'CosineSimilarity': 'Pred_Score'})\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:50:44.083561Z","iopub.execute_input":"2024-01-29T07:50:44.083917Z","iopub.status.idle":"2024-01-29T07:50:44.093600Z","shell.execute_reply.started":"2024-01-29T07:50:44.083890Z","shell.execute_reply":"2024-01-29T07:50:44.092849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_df = df3.drop(columns=['Text1', 'Text2','Text'])\ntransformer_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:50:44.094988Z","iopub.execute_input":"2024-01-29T07:50:44.095347Z","iopub.status.idle":"2024-01-29T07:50:44.108961Z","shell.execute_reply.started":"2024-01-29T07:50:44.095316Z","shell.execute_reply":"2024-01-29T07:50:44.108072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_df = transformer_df.rename(columns={'CosineSimilarity': 'Pred_Score'})\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:50:44.110049Z","iopub.execute_input":"2024-01-29T07:50:44.110402Z","iopub.status.idle":"2024-01-29T07:50:44.119105Z","shell.execute_reply.started":"2024-01-29T07:50:44.110375Z","shell.execute_reply":"2024-01-29T07:50:44.118326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_df['Pred_Score'] = transformer_df['Pred_Score'].apply(lambda x: 0 if x < 0 else x)\ntransformer_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:50:44.120324Z","iopub.execute_input":"2024-01-29T07:50:44.120602Z","iopub.status.idle":"2024-01-29T07:50:44.135084Z","shell.execute_reply.started":"2024-01-29T07:50:44.120571Z","shell.execute_reply":"2024-01-29T07:50:44.134136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_df.to_csv(\"pred_mar_a.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T07:50:44.135901Z","iopub.execute_input":"2024-01-29T07:50:44.136188Z","iopub.status.idle":"2024-01-29T07:50:44.146612Z","shell.execute_reply.started":"2024-01-29T07:50:44.136165Z","shell.execute_reply":"2024-01-29T07:50:44.145813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}